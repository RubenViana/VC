{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaU9_sOGzRD1"
      },
      "source": [
        "# Lab 10 - Task 2 Baseline\n",
        "\n",
        "In this class, we will develop a baseline for Task 2 using a subset of the lego dataset. We will model the task as an ordinal classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvfTDUXuzRD9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt, numpy as np, os, torch, random, cv2\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCiAkFspd8US"
      },
      "source": [
        "### Connect Colab to Drive (if the dataset is on drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQJFEi19d8US",
        "outputId": "e61902da-0b1d-4de2-d73a-69b7acc2a937"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXLs-GOgGB5a"
      },
      "outputs": [],
      "source": [
        "!unzip \"drive/MyDrive/Legos/photos.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBhCwhszREA"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "In the Lego dataset, the images are organized into folders according to the number of legos. In this notebook, we will only consider images with up to 4 legos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5IQVCmOzREB"
      },
      "outputs": [],
      "source": [
        "images_directory = \"photos\"\n",
        "\n",
        "# Obtain names of images for training and validation\n",
        "image_paths = []\n",
        "num_legos = []\n",
        "for dirpath, dirnames, filenames in os.walk(images_directory):\n",
        "    for filename in filenames:\n",
        "        # Check how many legos the image has\n",
        "        n = int(dirpath.split(os.sep)[-1])\n",
        "        num_legos.append(n)\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_paths.append(os.path.join(dirpath, filename))\n",
        "image_paths.sort()\n",
        "\n",
        "image_paths = np.asarray(image_paths)\n",
        "num_legos = torch.Tensor(num_legos).to(torch.int64)\n",
        "\n",
        "# Randomly split data into train (0), validation (1) and test (2) sets\n",
        "split = np.random.choice([0, 1, 2], len(image_paths), p=[0.8, 0.1, 0.1])\n",
        "\n",
        "train_indexes = np.where(split == 0)[0]\n",
        "valid_indexes = np.where(split == 1)[0]\n",
        "test_indexes = np.where(split == 2)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juTsr3Lld8UT"
      },
      "outputs": [],
      "source": [
        "class LegosDataset(Dataset):\n",
        "    def __init__(self, images_filenames, num_legos, transform=None):\n",
        "        self.images_filenames = images_filenames\n",
        "        self.transform = transform\n",
        "\n",
        "        # Transform number of legos into one hot encoding\n",
        "        self.labels = num_legos - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filename = self.images_filenames[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Read image\n",
        "        image = cv2.imread(image_filename)\n",
        "\n",
        "        # Convert from BGR to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply the same data augmentation to both input image and target mask\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAYHXPnzd8UT"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_workers = 2\n",
        "\n",
        "# Define transformations to be applied to data\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define datasets and dataloaders\n",
        "train_dataset = LegosDataset(image_paths[train_indexes], num_legos[train_indexes], transform=transform)\n",
        "valid_dataset = LegosDataset(image_paths[valid_indexes], num_legos[valid_indexes], transform=transform)\n",
        "test_dataset = LegosDataset(image_paths[test_indexes], num_legos[test_indexes], transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqWR_0VzRED"
      },
      "source": [
        "## Defining the model\n",
        "\n",
        "Load a pre-trained convolutional neural network of your own choice from torchvision. Do not forget to change the last layer to match the number of classes (4)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfK3c9RSzRED",
        "outputId": "ab418e17-f6ca-43b8-a4e5-a0b6852e3a26"
      },
      "outputs": [],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "model = # TODO\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1kRGiw_zREE"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDxDXlXud8UU"
      },
      "source": [
        "Define function to perform one iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxSdayviCWk5"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiUlq1FLd8UV"
      },
      "source": [
        "Define function to train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPbGtpwIMuT7"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73djngkzNkjD"
      },
      "source": [
        "Define loss, optimizer and train the model. Remember that we will model this regression task problem as a classification problem when choosing the loss function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmsUVGS6C0O1",
        "outputId": "9b97843d-0735-4c84-c7c5-58b30c44b489"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "loss_fn = # TODO\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = # TODO\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "# TODO - Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrQMAKFHzREG"
      },
      "source": [
        "## Analyse training evolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7W0PEy1d8UV"
      },
      "source": [
        "Plot loss and accuracy throughout training on train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr48TEVlzREH"
      },
      "outputs": [],
      "source": [
        "def plotTrainingHistory(train_history, val_history):\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(train_history['loss'], label='train')\n",
        "    plt.plot(val_history['loss'], label='val')\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(train_history['accuracy'], label='train')\n",
        "    plt.plot(val_history['accuracy'], label='val')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "3GfeNPc4zREI",
        "outputId": "b59237ea-0719-4285-dbcc-cdac49dc83e6"
      },
      "outputs": [],
      "source": [
        "plotTrainingHistory(train_history, val_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPZLw5cfzREI"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Evaluate the model in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtmFHipizREK",
        "outputId": "60261a6c-e7cc-4a8f-c2b5-ee438eeea4e7"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "# TODO\n",
        "\n",
        "# Evaluate model on test data\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-C6glKseuO"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In transfer learning, we often replace the head of the model (fully-connected layers responsible for classification) to fit the task. However, these new layers are not pre-trained and thus they contain an error that is backpropagated through the pre-trained part of the network during training. We can avoid this through a training strategy that is divided into two steps:\n",
        "* Freeze the pre-trained layers of the network so that their parameters are no longer updated during training and train only the head of the model\n",
        "* Unfreeze these layers and train the network as a whole.\n",
        "\n",
        "Implement this strategy and see the results!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
