{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaU9_sOGzRD1"
      },
      "source": [
        "# Lab 6: Neural Networks\n",
        "\n",
        "In this notebook we will learn how to train a simple Multilayer Perceptron for image classification using PyTorch. \n",
        "\n",
        "[Click here to check guide to install PyTorch locally.](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "You can find additional information [here](https://pytorch.org/tutorials/beginner/basics/intro.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvfTDUXuzRD9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBhCwhszREA"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "The torchvision package contains a few datasets. We will use the MNIST dataset of handwritten digits.\n",
        "\n",
        "The dataset comes separated into training and test sets. We will further separate the test set into two smaller sets: validation and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5IQVCmOzREB"
      },
      "outputs": [],
      "source": [
        "# Define transformations that are applied to the image\n",
        "data_aug = transforms.Compose([transforms.ToTensor()]) # ToTensor() transforms an image into a tensor, normalizing it into values between 0 and 1\n",
        "\n",
        "# Load training data from MNIST into directory defined in \"root\"\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "\n",
        "# Load test data from MNIST into directory defined in \"root\"\n",
        "validation_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "\n",
        "# Separate test images into validation (80%) and testing (20%)\n",
        "indices = list(range(len(validation_data)))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "test_size = 0.2 * len(indices)\n",
        "split = int(np.floor(test_size))\n",
        "val_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "val_sampler = SubsetRandomSampler(val_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a data loader that automatically fetches batches of images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByDvrH3z1uOT"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 # number of images loaded at each time\n",
        "num_workers = 2 # how many processes are used to load the data\n",
        "\n",
        "# Define data loaders for the train, test and validation data\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=val_sampler, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "test_dataloader = DataLoader(validation_data, sampler=test_sampler, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the Data\n",
        "\n",
        "Directly using the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the first sample of the training data (contains an image and its label)\n",
        "\n",
        "sample = training_data[0] \n",
        "\n",
        "# Get image and print its dimensions\n",
        "img = sample[0]\n",
        "print(img.shape)\n",
        "\n",
        "# Get label and print it\n",
        "label = sample[1]\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iterating over the data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in train_dataloader:\n",
        "  # Get images of the batch and print their dimensions\n",
        "  imgs = batch[0]\n",
        "  print(imgs.shape)\n",
        "\n",
        "  # Get labels of each image in the batch and print them\n",
        "  labels = batch[1]\n",
        "  print(labels)\n",
        "\n",
        "  # Show first image of the batch\n",
        "  plt.imshow(imgs[0][0,:,:], cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  \n",
        "  break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqWR_0VzRED"
      },
      "source": [
        "## Defining the model\n",
        "\n",
        "Create an MLP with the following structure: \n",
        "\n",
        "1. Dense/linear layer that takes the images as a flattened input vector and generates an output of 512 of dimension.\n",
        "2. ReLU activation layer\n",
        "3. Dense/linear layer with 512 input and output\n",
        "3. ReLU activation layer\n",
        "4. Dense/linear layer with 10 output channels (10 classes of MNIST)\n",
        "\n",
        "You can use PyTorch's layers: https://pytorch.org/docs/stable/nn.html (Conv2d, ReLU, Linear, MaxPool2d, Dropout, Flatten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfK3c9RSzRED"
      },
      "outputs": [],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        # TODO: Define model layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TODO: Apply layers to input x and return result\n",
        "\n",
        "model = NeuralNetwork().to(device) # put model in device (GPU or CPU)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpret the implemented architecture and try to answer the following questions:\n",
        "\n",
        "a) What is the shape (width, and # of channels) of the output tensor after the first layer?\n",
        "\n",
        "b) And after the first 3 layers (dense+dense+dense)?\n",
        "\n",
        "c) How many parameters (weights) does the model have? Contrary to Keras, PyTorch does not have an official method for counting the number of parameters of a model, but you can use [torchsummary](https://pypi.org/project/torch-summary/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install torch-summary\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1kRGiw_zREE"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNa9_1jhzREE"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "loss_fn = nn.CrossEntropyLoss() # already includes the Softmax activation\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define one iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxSdayviCWk5"
      },
      "outputs": [],
      "source": [
        "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
        "    if is_train:\n",
        "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
        "  \n",
        "    # Get number of batches\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # Set model to train mode or evaluation mode\n",
        "    if is_train:\n",
        "      model.train()\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    # Define variables to save predictions and labels during the epoch\n",
        "    total_loss = 0.0\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    # Enable/disable gradients based on whether the model is in train or evaluation mode\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "\n",
        "      # Analyse all batches\n",
        "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "          \n",
        "          # Put data in same device as model (GPU or CPU)\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # Forward pass to obtain prediction of the model\n",
        "          pred = model(X)\n",
        "          \n",
        "          # Compute loss between prediction and ground-truth\n",
        "          loss = loss_fn(pred, y)\n",
        "\n",
        "          # Backward pass\n",
        "          if is_train:\n",
        "            # Reset gradients in optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # Calculate gradients by backpropagating loss\n",
        "            loss.backward()\n",
        "            # Update model weights based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "          # Apply softmax activation to obtain final prediction\n",
        "          probs = F.softmax(pred, dim=1)\n",
        "          final_pred = torch.argmax(probs, dim=1)\n",
        "\n",
        "          # Save training metrics\n",
        "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
        "\n",
        "          # Add predictions\n",
        "          preds.extend(final_pred.cpu().numpy())\n",
        "          labels.extend(y.cpu().numpy())\n",
        "\n",
        "    return total_loss / num_batches, accuracy_score(labels, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define training cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmsUVGS6C0O1"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "train_history = {'loss': [], 'accuracy': []}\n",
        "val_history = {'loss': [], 'accuracy': []}\n",
        "best_val_loss = np.inf\n",
        "\n",
        "# Training cycle\n",
        "print(\"Start training...\")\n",
        "for t in range(num_epochs):\n",
        "    print(f\"\\nEpoch {t+1}\")\n",
        "\n",
        "    # Train model for one iteration on training data\n",
        "    train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
        "    print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
        "    \n",
        "    # Evaluate model on validation data\n",
        "    val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
        "    print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
        "\n",
        "    # Save model when validation loss improves\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "      torch.save(save_dict, 'best_model.pth')\n",
        "\n",
        "    # Save latest model\n",
        "    save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "    torch.save(save_dict, 'latest_model.pth')\n",
        "\n",
        "    # Save training history for plotting purposes\n",
        "    train_history[\"loss\"].append(train_loss)\n",
        "    train_history[\"accuracy\"].append(train_acc)\n",
        "\n",
        "    val_history[\"loss\"].append(val_loss)\n",
        "    val_history[\"accuracy\"].append(val_acc)\n",
        "    \n",
        "print(\"Finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrQMAKFHzREG"
      },
      "source": [
        "## Analyse training evolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot loss and accuracy throughout training on train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr48TEVlzREH"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HPZLw5cfzREI"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Evaluate the model in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtmFHipizREK"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1yyEC9pzREJ"
      },
      "outputs": [],
      "source": [
        "def showErrors(model, dataloader, num_examples=20):    \n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    for ind, (X, y) in enumerate(dataloader):\n",
        "      if ind >= 20: break\n",
        "      X, y = X.to(device), y.to(device)    \n",
        "      pred = model(X)\n",
        "      probs = F.softmax(pred, dim=1)\n",
        "      final_pred = torch.argmax(probs, dim=1)\n",
        "\n",
        "      plt.subplot(10, 10, ind + 1)\n",
        "      plt.axis(\"off\")\n",
        "      plt.text(0, -1, y[0].item(), fontsize=14, color='green') # correct\n",
        "      plt.text(8, -1, final_pred[0].item(), fontsize=14, color='red')  # predicted\n",
        "      plt.imshow(X[0][0,:,:].cpu(), cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh38evzTzREL"
      },
      "outputs": [],
      "source": [
        "showErrors(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-C6glKseuO"
      },
      "source": [
        "## Additional Challenges\n",
        "\n",
        "a) As the test accuracy should show, the MNIST dataset is not very challenging, change the code to use Fashion-MNIST and compare the results.\n",
        "\n",
        "b) Do the same for the CIFAR10 (or CIFAR100) dataset. Note that, in this case, each image is a 32x32 color image; convert it to grayscale or concatenate the RGB channels in one single vector (e.g. using the reshape method).\n",
        "\n",
        "c) The test accuracy for CIFAR is significantly worse. Try improving the results by using: 1) a deeper architecture, and 2) a different optmizer.\n",
        "\n",
        "You can load the datasets from [here](https://pytorch.org/vision/stable/datasets.html).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nn_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
