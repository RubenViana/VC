{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first lab is to present a small introduction to image processing using OpenCV. In each section, you can find:\n",
    "* a small example - analyse the code and try it\n",
    "* some exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements for this tutorial\n",
    "! pip install opencv-python\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer, you can convert this notebook to a Python script by uncommenting the following command\n",
    "! pip install nbconvert\n",
    "! jupyter nbconvert --to script 01-introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataDir = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Images â€“ read, write and display; ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/rubis/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Waiting for user to press a key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after user pressed a key\n",
    "cv2.destroyWindow(\"ml.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 380\n",
      "width: 308\n",
      "channels: 3\n"
     ]
    }
   ],
   "source": [
    "# Check image size\n",
    "h, w, c = img.shape\n",
    "print(f'height: {h}')\n",
    "print(f'width: {w}')\n",
    "print(f'channels: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving image in bmp format\n",
    "cv2.imwrite('ml_new.bmp', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1 - Read any other color image from a file, show the mouse cursor over the image, and the coordinates and RGB components of the pixel under the cursor. When the user clicks on the mouse, let him modify the RGB components of the selected pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (307, 330)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (278, 311)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (254, 296)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (234, 282)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (219, 271)\n",
      "Pixel RGB: [246 246 246]\n",
      "Coordinates: (208, 263)\n",
      "Pixel RGB: [17 19 19]\n",
      "Coordinates: (200, 256)\n",
      "Pixel RGB: [174 176 176]\n",
      "Coordinates: (193, 249)\n",
      "Pixel RGB: [180 182 182]\n",
      "Coordinates: (191, 243)\n",
      "Pixel RGB: [168 167 169]\n",
      "Coordinates: (189, 236)\n",
      "Pixel RGB: [84 92 85]\n",
      "Coordinates: (187, 230)\n",
      "Pixel RGB: [194 206 200]\n",
      "Coordinates: (185, 224)\n",
      "Pixel RGB: [117 146 131]\n",
      "Coordinates: (182, 217)\n",
      "Pixel RGB: [ 38 100  64]\n",
      "Coordinates: (181, 212)\n",
      "Pixel RGB: [ 73 144 104]\n",
      "Coordinates: (179, 206)\n",
      "Pixel RGB: [ 74 145 105]\n",
      "Coordinates: (178, 203)\n",
      "Pixel RGB: [124 163 117]\n",
      "Coordinates: (177, 199)\n",
      "Pixel RGB: [192 201 180]\n",
      "Coordinates: (176, 197)\n",
      "Pixel RGB: [215 247 242]\n",
      "Coordinates: (176, 195)\n",
      "Pixel RGB: [189 221 226]\n",
      "Coordinates: (176, 194)\n",
      "Pixel RGB: [222 244 249]\n",
      "Coordinates: (176, 193)\n",
      "Pixel RGB: [247 255 255]\n",
      "Coordinates: (176, 192)\n",
      "Pixel RGB: [252 252 252]\n",
      "Coordinates: (176, 192)\n",
      "Pixel RGB: [252 252 252]\n",
      "Coordinates: (176, 191)\n",
      "Pixel RGB: [254 254 254]\n",
      "Coordinates: (176, 191)\n",
      "Pixel RGB: [254 254 254]\n",
      "Coordinates: (176, 190)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (177, 188)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (178, 187)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (178, 185)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (179, 184)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (179, 181)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (180, 178)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (181, 176)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (182, 174)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (182, 172)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (182, 170)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (183, 169)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (184, 167)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (184, 165)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (186, 161)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (187, 162)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (188, 163)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (189, 165)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (189, 166)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (190, 167)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (190, 167)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (191, 168)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (191, 168)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (192, 169)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (192, 170)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (193, 171)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (194, 172)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (194, 172)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (195, 171)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (196, 170)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (197, 168)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (199, 166)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (201, 163)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (201, 155)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (202, 145)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (203, 134)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (204, 123)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (206, 111)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (208, 99)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (210, 86)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (213, 72)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (217, 58)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (220, 43)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (223, 29)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (227, 16)\n",
      "Pixel RGB: [255 255 255]\n",
      "Coordinates: (230, 4)\n",
      "Pixel RGB: [255 255 255]\n"
     ]
    }
   ],
   "source": [
    "# Open an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "def paint_coordinates(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        print(f'Coordinates: ({x}, {y})')\n",
    "        print(f'Pixel RGB: {img[y][x]}')\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        img[y][x] = [255, 0, 0]\n",
    "\n",
    "# Create a window\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.setMouseCallback('image', paint_coordinates)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2 - Allow the user to select a region of interest (ROI) in the image, by clicking on two points that identify two opposite corners of the selected ROI, and save the ROI into another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "roi = cv2.selectROI(img)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# print(roi)\n",
    "\n",
    "# Crop image\n",
    "cropped = img[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "\n",
    "cv2.imwrite('ml_cropped.jpg', cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Images â€“ representation, grayscale and color, color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "m = np.ones((100,200,1), np.uint8)\n",
    "\n",
    "# Change the intensity to 100\n",
    "m = m * 100\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Grayscale image', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line with thickness of 5 px\n",
    "cv2.line(m, (0,0), (200,100), 255, 5)\n",
    "cv2.line(m, (200, 0), (0, 100), 255, 5)\n",
    "cv2.imshow('Grayscale image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image with diagonals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1 - Create a color image with 100(lines)x200(columns) pixels with yellow color; draw the two diagonals of the image, one in red color, the other in blue color. Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellow image\n",
    "m = np.ones((100,200,3))\n",
    "\n",
    "# Change color to yellow\n",
    "m[:,:,0] = 0\n",
    "m[:,:,1] = 255\n",
    "m[:,:,2] = 255\n",
    "\n",
    "# Draw red line\n",
    "cv2.line(m, (0,0), (200,100), (0, 0, 255), 5)\n",
    "\n",
    "# Draw blue line\n",
    "cv2.line(m, (200, 0), (0, 100), (255, 0, 0), 5)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Yellow image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Yellow image with diagonals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2 - Read any color image, in RGB format, display it in one window, convert it to grayscale, display the grayscale image in another window and save the grayscale image to a different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color image\n",
    "color_img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Show color image\n",
    "cv2.imshow('Color image', color_img)\n",
    "\n",
    "# Convert color image to grayscale\n",
    "gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show grayscale image\n",
    "cv2.imshow('Grayscale image', gray_img)\n",
    "\n",
    "# Save grayscale image\n",
    "cv2.imwrite('ml_gray.jpg', gray_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.3 - Split the 3 RGB channels and show each channel in a separate window. Add a constant value to one of the channels, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Split image into channels\n",
    "blue_channel, green_channel, red_channel = cv2.split(img)\n",
    "\n",
    "# Set a constant value to blue channel\n",
    "blue_channel = 255 * np.ones_like(blue_channel)\n",
    "\n",
    "# Merge channels\n",
    "merged = cv2.merge((blue_channel, green_channel, red_channel))\n",
    "\n",
    "# Show channels\n",
    "cv2.imshow('Red channel', red_channel)\n",
    "cv2.imshow('Green channel', green_channel)\n",
    "cv2.imshow('Blue channel', blue_channel)\n",
    "\n",
    "# Show merged image\n",
    "cv2.imshow('Merged image', merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.4 - Convert the image to HSV, split the 3 HSV channels and show each channel in a separate window. Add a constant value to saturation channel, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Video â€“ acquisition and simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    # Wait for user to press s to save frame\n",
    "    if cv2.waitKey(1) == ord('s'):\n",
    "        frame_name = 'frame' + str(frame_nr) + '.png'\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        cv2.imshow(\"Saved frame: \" + frame_name, frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Saved frame: \" + frame_name)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1 - Using the previous example as the baseline, implement a script that acquires the video from the webcam, converts it to grayscale, and shows the frames in binary format (i.e. the intensity of each pixel is 0 or 255); use a threshold value of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Display the resulting frameq\n",
    "    cv2.imshow('webcam', thresholded)\n",
    "\n",
    "    # Wait for user to press s to save frame\n",
    "    if cv2.waitKey(1) == ord('s'):\n",
    "        frame_name = 'frame' + str(frame_nr) + '.png'\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        cv2.imshow(\"Saved frame: \" + frame_name, frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Saved frame: \" + frame_name)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2 - Implement a simple detection/tracking algorithm for colored objects, using the following steps:\n",
    "1) take each frame of the video;\n",
    "2) convert from BGR to HSV color-space;\n",
    "3) threshold the HSV image for a range of color values (creating a binary image);\n",
    "4) extract the objects of the selected range (with a bitwise AND operation, using as operands the original and the binary image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/rubis/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    # mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    # res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    # Invert the frame\n",
    "    res = cv2.bitwise_not(frame)\n",
    "\n",
    "    # Display the original frame\n",
    "    cv2.imshow('webcam original', frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam blue', res)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
