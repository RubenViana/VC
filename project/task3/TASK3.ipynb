{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "quRY70Qf-q4E",
        "7mzCknvmisk7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv8s.pt"
      ],
      "metadata": {
        "id": "quRY70Qf-q4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z2pSbvgB8WgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9325ae6-a907-407f-8014-f0cf90bb4a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths to your main folder in Google Drive and the destination folder in Colab\n",
        "source_main_folder = '/content/drive/MyDrive/VCOM_TASK3/photos'\n",
        "destination_images_path = '/content/data/images'\n",
        "destination_annotations_path = '/content/data/annotations'\n",
        "\n",
        "# Create destination directories if they don't exist\n",
        "os.makedirs(destination_images_path, exist_ok=True)\n",
        "os.makedirs(destination_annotations_path, exist_ok=True)\n",
        "\n",
        "# Copy all images and XML files from subfolders to destination directories\n",
        "for root, dirs, files in os.walk(source_main_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            shutil.copy(os.path.join(root, file), os.path.join(destination_images_path, file))\n",
        "        elif file.endswith('.xml'):\n",
        "            shutil.copy(os.path.join(root, file), os.path.join(destination_annotations_path, file))\n",
        "\n",
        "# List some files to confirm\n",
        "print(\"Images:\", os.listdir(destination_images_path)[:5])\n",
        "print(\"Annotations:\", os.listdir(destination_annotations_path)[:5])\n"
      ],
      "metadata": {
        "id": "sTkjy5vH-xm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "G40WmKFlEd2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Create directories for train and test splits\n",
        "os.makedirs('/content/data/train/images', exist_ok=True)\n",
        "os.makedirs('/content/data/train/annotations', exist_ok=True)\n",
        "os.makedirs('/content/data/test/images', exist_ok=True)\n",
        "os.makedirs('/content/data/test/annotations', exist_ok=True)\n",
        "\n",
        "# List all images\n",
        "all_images = [f for f in os.listdir(destination_images_path) if f.endswith('.jpg')]\n",
        "\n",
        "# Shuffle and split the data\n",
        "random.shuffle(all_images)\n",
        "split_index = int(len(all_images) * 0.8)\n",
        "train_images = all_images[:split_index]\n",
        "test_images = all_images[split_index:]\n",
        "\n",
        "# Move files to train and test directories\n",
        "for image in train_images:\n",
        "    shutil.move(os.path.join(destination_images_path, image), '/content/data/train/images/' + image)\n",
        "    xml_file = image.replace('.jpg', '.xml')\n",
        "    shutil.move(os.path.join(destination_annotations_path, xml_file), '/content/data/train/annotations/' + xml_file)\n",
        "\n",
        "for image in test_images:\n",
        "    shutil.move(os.path.join(destination_images_path, image), '/content/data/test/images/' + image)\n",
        "    xml_file = image.replace('.jpg', '.xml')\n",
        "    shutil.move(os.path.join(destination_annotations_path, xml_file), '/content/data/test/annotations/' + xml_file)\n",
        "\n",
        "# Function to convert VOC to YOLO format\n",
        "def convert_voc_to_yolo(voc_folder, yolo_folder, img_folder):\n",
        "    if not os.path.exists(yolo_folder):\n",
        "        os.makedirs(yolo_folder)\n",
        "\n",
        "    for xml_file in os.listdir(voc_folder):\n",
        "        if not xml_file.endswith('.xml'):\n",
        "            continue\n",
        "\n",
        "        tree = ET.parse(os.path.join(voc_folder, xml_file))\n",
        "        root = tree.getroot()\n",
        "\n",
        "        img_file = root.find('filename').text\n",
        "        img_path = os.path.join(img_folder, img_file)\n",
        "\n",
        "        width = int(root.find('size/width').text)\n",
        "        height = int(root.find('size/height').text)\n",
        "\n",
        "        with open(os.path.join(yolo_folder, xml_file.replace('.xml', '.txt')), 'w') as yolo_file:\n",
        "            for obj in root.findall('object'):\n",
        "                class_id = 0  # Assuming all objects are \"lego\" and the class_id is 0\n",
        "                bndbox = obj.find('bndbox')\n",
        "                xmin = int(bndbox.find('xmin').text)\n",
        "                ymin = int(bndbox.find('ymin').text)\n",
        "                xmax = int(bndbox.find('xmax').text)\n",
        "                ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "                x_center = (xmin + xmax) / 2.0 / width\n",
        "                y_center = (ymin + ymax) / 2.0 / height\n",
        "                bbox_width = (xmax - xmin) / width\n",
        "                bbox_height = (ymax - ymin) / height\n",
        "\n",
        "                yolo_file.write(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n",
        "\n",
        "# Convert training and testing annotations\n",
        "convert_voc_to_yolo('/content/data/train/annotations', '/content/data/train/labels', '/content/data/train/images')\n",
        "convert_voc_to_yolo('/content/data/test/annotations', '/content/data/test/labels', '/content/data/test/images')\n"
      ],
      "metadata": {
        "id": "_5erwTM6A8FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare YOLO dataset configuration file\n",
        "dataset_yaml = \"\"\"\n",
        "train: /content/data/train/images\n",
        "val: /content/data/test/images\n",
        "\n",
        "nc: 1  # number of classes\n",
        "names: ['lego']  # class names\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/dataset.yaml', 'w') as file:\n",
        "    file.write(dataset_yaml)\n"
      ],
      "metadata": {
        "id": "trWF-CpdD6oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and train the YOLO model with custom image size\n",
        "model = YOLO('yolov8s.pt')\n",
        "model.train(data='/content/dataset.yaml', epochs=20, imgsz=320)\n"
      ],
      "metadata": {
        "id": "AEe2Gq0fD-Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R-CNN"
      ],
      "metadata": {
        "id": "7mzCknvmisk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths to your main folder in Google Drive and the destination folder in Colab\n",
        "source_main_folder = '/content/drive/MyDrive/VCOM_TASK3/photos'\n",
        "destination_images_path = '/content/data/images'\n",
        "destination_annotations_path = '/content/data/annotations'\n",
        "\n",
        "# Create destination directories if they don't exist\n",
        "os.makedirs(destination_images_path, exist_ok=True)\n",
        "os.makedirs(destination_annotations_path, exist_ok=True)\n",
        "\n",
        "# Copy all images and XML files from subfolders to destination directories\n",
        "for root, dirs, files in os.walk(source_main_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            shutil.copy(os.path.join(root, file), os.path.join(destination_images_path, file))\n",
        "        elif file.endswith('.xml'):\n",
        "            shutil.copy(os.path.join(root, file), os.path.join(destination_annotations_path, file))\n",
        "\n",
        "# List some files to confirm\n",
        "print(\"Images:\", os.listdir(destination_images_path)[:5])\n",
        "print(\"Annotations:\", os.listdir(destination_annotations_path)[:5])\n"
      ],
      "metadata": {
        "id": "9YoTRdFP2Yvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc65c97e-0fd5-4487-91c5-dcaade680472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Images: ['IMG_20201208_032220.jpg', 'IMG_20201211_164736.jpg', 'IMG_20201211_170628.jpg', 'IMG_20201203_091548.jpg', '0_T123_original_3460_1609896039750.jpg']\n",
            "Annotations: ['IMG_20201208_030904.xml', '0_EQwj_original_60479_1609884613634.xml', 'IMG_20201211_164201.xml', 'IMG_20201204_224650.xml', 'IMG_20201203_091340.xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch torchvision"
      ],
      "metadata": {
        "id": "tIoErbwq2c2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2568b20-9b53-40d8-9a32-2c25ee1d1426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.ops import boxes as box_ops\n",
        "\n",
        "# Create directories for train and test splits\n",
        "os.makedirs('/content/data/train/images', exist_ok=True)\n",
        "os.makedirs('/content/data/train/annotations', exist_ok=True)\n",
        "os.makedirs('/content/data/test/images', exist_ok=True)\n",
        "os.makedirs('/content/data/test/annotations', exist_ok=True)\n",
        "\n",
        "# List all images\n",
        "all_images = [f for f in os.listdir(destination_images_path) if f.endswith('.jpg')]\n",
        "\n",
        "# Shuffle and split the data\n",
        "random.shuffle(all_images)\n",
        "split_index = int(len(all_images) * 0.8)\n",
        "train_images = all_images[:split_index]\n",
        "test_images = all_images[split_index:]\n",
        "\n",
        "# Move files to train and test directories\n",
        "for image in train_images:\n",
        "    shutil.move(os.path.join(destination_images_path, image), '/content/data/train/images/' + image)\n",
        "    xml_file = image.replace('.jpg', '.xml')\n",
        "    shutil.move(os.path.join(destination_annotations_path, xml_file), '/content/data/train/annotations/' + xml_file)\n",
        "\n",
        "for image in test_images:\n",
        "    shutil.move(os.path.join(destination_images_path, image), '/content/data/test/images/' + image)\n",
        "    xml_file = image.replace('.jpg', '.xml')\n",
        "    shutil.move(os.path.join(destination_annotations_path, xml_file), '/content/data/test/annotations/' + xml_file)\n",
        "\n",
        "# Define a custom dataset class\n",
        "class LegoDataset(Dataset):\n",
        "    def __init__(self, images_folder, annotations_folder, transforms=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.annotations_folder = annotations_folder\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(images_folder)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.imgs[idx]\n",
        "        img_path = os.path.join(self.images_folder, img_name)\n",
        "        annotation_path = os.path.join(self.annotations_folder, img_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes = []\n",
        "        for obj in root.findall('object'):\n",
        "            bndbox = obj.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.ones((len(boxes),), dtype=torch.int64)  # assuming all instances are \"lego\"\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': image_id,\n",
        "            'area': area,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "# Data transforms\n",
        "transform = T.Compose([\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = LegoDataset('/content/data/train/images', '/content/data/train/annotations', transforms=transform)\n",
        "test_dataset = LegoDataset('/content/data/test/images', '/content/data/test/annotations', transforms=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Load pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes = 2  # 1 class (lego) + background\n",
        "\n",
        "# Get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# Replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# Define training function\n",
        "def train_model(model, data_loader, device):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, targets in data_loader:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += losses.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n"
      ],
      "metadata": {
        "id": "7666Tl4K3KQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "train_model(model, train_data_loader, device)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'faster_rcnn_lego.pth')"
      ],
      "metadata": {
        "id": "t84g6dJp3NGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation"
      ],
      "metadata": {
        "id": "Mpr3dUzdCeaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Paths to main folder in Google Drive and the destination folder in Colab\n",
        "segmentation_main_folder = '/content/drive/MyDrive/photos'\n",
        "segmentation_images_path = '/content/data/segmentation/images'\n",
        "segmentation_destination_folder = '/content/data/segmentation/segmented_images'\n",
        "\n",
        "# Create destination directories if they don't exist\n",
        "os.makedirs(segmentation_images_path, exist_ok=True)\n",
        "os.makedirs(segmentation_destination_folder, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3qAINhELnr",
        "outputId": "4d0f22a7-71af-4652-9d11-5e177b3c16ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Copy all images and XML files from subfolders to destination directories\n",
        "for root, dirs, files in os.walk(segmentation_main_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            shutil.copy(os.path.join(root, file), os.path.join(segmentation_images_path, file))\n",
        "\n",
        "# List some files to confirm\n",
        "print(\"Images:\", os.listdir(segmentation_images_path)[:5])\n"
      ],
      "metadata": {
        "id": "tS6dFJ8OCh1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "aa060e87-3e66-4e98-cc18-31c1b7278928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d7580ebcb291>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_images_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# List some files to confirm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = YOLO('/content/YOLO_model.pt')\n",
        "\n",
        "# Get the first n image file paths\n",
        "def get_first_n_images(folder_path):\n",
        "    all_files = os.listdir(folder_path)\n",
        "    image_files = [file for file in all_files if file.endswith('.jpg')]\n",
        "    image_files.sort()  # Sorting to ensure consistency\n",
        "    first_n_images = image_files[:3]\n",
        "    return [os.path.join  (folder_path, image) for image in first_n_images]\n",
        "\n",
        "first_n_images = get_first_n_images(segmentation_images_path)\n",
        "\n",
        "# Function to apply GrabCut\n",
        "def apply_grabcut(image, bounding_box):\n",
        "    x1, y1, x2, y2 = map(int, bounding_box.tolist())\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    cropped_image = cv2.GaussianBlur(cropped_image, (5, 5), 0)\n",
        "    gray_cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply global binary threshold\n",
        "    _, binary_cropped_image = cv2.threshold(gray_cropped_image, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # GrabCut segmentation\n",
        "    mask = np.zeros(cropped_image.shape[:2], np.uint8)\n",
        "\n",
        "    bgd_model = np.zeros((1, 65), np.float64)\n",
        "    fgd_model = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    rect = (1, 1, cropped_image.shape[1] - 2, cropped_image.shape[0] - 2)\n",
        "    cv2.grabCut(cropped_image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "    segmented_cropped_image = cropped_image * mask2[:, :, np.newaxis]\n",
        "\n",
        "    # k-means clustering\n",
        "    pixel_values = segmented_cropped_image.reshape((-1, 3))\n",
        "    pixel_values = np.float32(pixel_values)\n",
        "\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.2)\n",
        "    _, labels, centers = cv2.kmeans(pixel_values, 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    centers = np.uint8(centers)\n",
        "    segmented_image = centers[labels.flatten()]\n",
        "    segmented_image = segmented_image.reshape(segmented_cropped_image.shape)\n",
        "\n",
        "    # Apply morphological operations\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    segmented_image = cv2.morphologyEx(segmented_cropped_image, cv2.MORPH_OPEN, kernel)\n",
        "    segmented_image = cv2.morphologyEx(segmented_image, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    image[y1:y2, x1:x2] = segmented_image\n",
        "\n",
        "    segmented_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    # segmented_image_resized = cv2.resize(segmented_image_bgr, (800, 800))\n",
        "\n",
        "    return segmented_image\n",
        "\n",
        "\n",
        "def detect_and_segment(image_path, model):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Improve the contrast of the image\n",
        "    image_lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(image_lab)\n",
        "    l = cv2.equalizeHist(l)\n",
        "    image_lab = cv2.merge((l, a, b))\n",
        "    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    results = model(image)\n",
        "\n",
        "    # Apply segmentation to each detected bounding box\n",
        "    segmented_images = [apply_grabcut(image, bbox) for bbox in results[0].boxes.xyxy]\n",
        "\n",
        "    return segmented_images\n",
        "\n",
        "for i, photo_path in enumerate(first_n_images):\n",
        "    segmented_images = detect_and_segment(photo_path, model)\n",
        "\n",
        "    for j, segmented_image in enumerate(segmented_images):\n",
        "        segmented_image_filename = os.path.join(segmentation_destination_folder, f\"segmented_{i+1}_{j+1}.jpg\")\n",
        "\n",
        "        cv2.imwrite(segmented_image_filename, segmented_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9-EYV_fzkyF",
        "outputId": "4652f1f9-cfb4-4e8f-d152-aa0df2a8e19f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.31)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.2.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "\n",
            "0: 640x480 1 bowl, 570.5ms\n",
            "Speed: 6.5ms preprocess, 570.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        }
      ]
    }
  ]
}